{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1-isX6Gz3ozonTm3qMBnllxBDgI8Gr6Pw",
      "authorship_tag": "ABX9TyPNXoOJDHc2uE1wmnYWzPV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huunghia160799/CS224W-Stanford/blob/master/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmzk4OvqlRv9",
        "colab_type": "code",
        "outputId": "f636f060-e65b-4ab9-cf89-d71b065ca394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "from functools import reduce\n",
        "\n",
        "n = 5\n",
        "phi = [[None for i in range(n + 1)] for i in range(n + 1)]\n",
        "\n",
        "phi[1][2] = phi[3][4] = np.array([[1, 0.9], [0.9, 1]])\n",
        "phi[2][3] = phi[3][5] = np.array([[0.1, 1], [1, 0.1]])\n",
        "phi[2][2] = phi[4][4] = np.array([[1, 0.1], [0.1, 1]])\n",
        "\n",
        "belief = [None for i in range(n + 1)]\n",
        "\n",
        "# term = phi[1][2].dot(phi[2][3].dot(phi[3][4].dot(phi[4][4])) + phi[2][3].dot(phi[3][5]))\n",
        "# term = reduce(np.dot, [phi[1][2], phi[2][3], phi[3][4], phi[4][4], phi[3][5]])\n",
        "# term\n",
        "\n",
        "post_3 = phi[3][4].dot(phi[4][4].dot(np.array([0, 1])) + phi[3][5].dot(np.array([1, 1])))\n",
        "post_2 = phi[2][2].dot(np.array([1, 0])) + phi[2][3].dot(post_3)\n",
        "unnormalized = phi[1][2].dot(post_2)\n",
        "belief[1] = unnormalized / np.sum(unnormalized)\n",
        "\n",
        "unnormalized = phi[1][2].T.dot(np.ones(2)) + phi[2][3].dot(post_3)\n",
        "belief[2] = unnormalized / np.sum(unnormalized)\n",
        "\n",
        "post_2 = phi[1][2].T.dot(np.ones(2)) + phi[2][2].dot(np.array([1, 0]))\n",
        "unnormalized = phi[3][4].dot(phi[4][4].dot(np.array([0, 1])) + phi[3][5].dot(np.array([1, 1]))) + phi[2][3].T.dot(post_2)\n",
        "belief[3] = unnormalized / np.sum(unnormalized)\n",
        "\n",
        "post_3 = phi[2][3].T.dot(post_2) + phi[3][4].dot(phi[4][4].dot(np.array([0, 1])))\n",
        "unnormalized = phi[3][5].T.dot(post_3)\n",
        "belief[5] = unnormalized / np.sum(unnormalized)\n",
        "\n",
        "post_3 = phi[2][3].T.dot(post_2) + phi[3][5].dot(np.ones(2))\n",
        "unnormalized = phi[3][4].T.dot(post_3)\n",
        "belief[4] = unnormalized / np.sum(unnormalized)\n",
        "\n",
        "for i in range(1, n + 1):\n",
        "    print(\"{}: {}\".format(i, belief[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: [0.50322818 0.49677182]\n",
            "2: [0.50378611 0.49621389]\n",
            "3: [0.46140652 0.53859348]\n",
            "4: [0.4971916 0.5028084]\n",
            "5: [0.54922217 0.45077783]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmAX8Gbm0sza",
        "colab_type": "text"
      },
      "source": [
        "# 4. GNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdLeScc9T8Up",
        "colab_type": "code",
        "outputId": "a956a256-73df-41d2-f3cc-dad7a463fd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd /content/drive/My Drive/CS224W Stanford: Machine Learning in Graphs/hw2/q4_starter_code\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS224W Stanford: Machine Learning in Graphs/hw2/q4_starter_code\n",
            "/content/drive/My Drive/CS224W Stanford: Machine Learning in Graphs/hw2/q4_starter_code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8etJsCj70wwa",
        "colab_type": "code",
        "outputId": "1b89c408-ddcb-40a8-e0c9-6f2cd756f89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch torch-geometric seaborn\n",
        "!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/35/8a65fc0b685d916f5f70199d6ad6f19bb002dc3a547a3fe5b68d60047f3b/torch_geometric-1.4.3.tar.gz (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.16.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (46.1.3)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.4.3-cp36-none-any.whl size=234873 sha256=e3d6d2296de5eae8459829644f506904a3ff441f421cc93f0bfc32bdf6488821\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/c1/09/8693feee3f97e440d68b09abfca8b4c1e97150ace350b5003f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-geometric-1.4.3\n",
            "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 1.0MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (15.2MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2MB 209kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.2)\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.0.4 torch-sparse-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N_TlIKoT6Ka",
        "colab_type": "code",
        "outputId": "33017c59-0cdb-4988-e129-7a00531f7335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "def parse_optimizer(parser):\n",
        "    opt_parser = parser.add_argument_group()\n",
        "    opt_parser.add_argument('--opt', dest='opt', type=str,\n",
        "            help='Type of optimizer')\n",
        "    opt_parser.add_argument('--opt-scheduler', dest='opt_scheduler', type=str,\n",
        "            help='Type of optimizer scheduler. By default none')\n",
        "    opt_parser.add_argument('--opt-restart', dest='opt_restart', type=int,\n",
        "            help='Number of epochs before restart (by default set to 0 which means no restart)')\n",
        "    opt_parser.add_argument('--opt-decay-step', dest='opt_decay_step', type=int,\n",
        "            help='Number of epochs before decay')\n",
        "    opt_parser.add_argument('--opt-decay-rate', dest='opt_decay_rate', type=float,\n",
        "            help='Learning rate decay ratio')\n",
        "    opt_parser.add_argument('--lr', dest='lr', type=float,\n",
        "            help='Learning rate.')\n",
        "    opt_parser.add_argument('--clip', dest='clip', type=float,\n",
        "            help='Gradient clipping.')\n",
        "    opt_parser.add_argument('--weight_decay', type=float,\n",
        "            help='Optimizer weight decay.')\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDsqO6WYgDH3",
        "colab_type": "text"
      },
      "source": [
        "## models.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDsFFe65WlfH",
        "colab_type": "code",
        "outputId": "06619d0d-8d8f-43e5-9d2b-51e775bffb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile models.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "import inspect\n",
        "\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, model_type, task='node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.task = task\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GCN':\n",
        "            return pyg_nn.GCNConv\n",
        "        elif model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Each layer in GNN should consist of a convolution (specified in model_type),\n",
        "        # a non-linearity (use RELU), and dropout. \n",
        "        # HINT: the __init__ function contains parameters you will need. You may \n",
        "        # also find pyg_nn.global_max_pool useful for graph classification.\n",
        "        # Our implementation is ~6 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        \n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)\n",
        "\n",
        "\n",
        "class GraphSage(pyg_nn.MessagePassing):\n",
        "    \"\"\"Non-minibatch version of GraphSage.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, reducer='mean', \n",
        "                 normalize_embedding=True):\n",
        "        super(GraphSage, self).__init__(aggr='mean')\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the forward function. \n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.agg_lin = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if normalize_embedding:\n",
        "            self.normalize_emb = True\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        num_nodes = x.size(0)\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Given x, perform the aggregation and pass it through a MLP with skip-\n",
        "        # connection. Place the result in out. \n",
        "        # HINT: It may be useful to read the pyg_nn implementation of GCNConv,\n",
        "        # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # Our implementation is ~4 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        # residual = x\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
        "        self_x = self.agg_lin(x)\n",
        "        # x = F.relu(x)\n",
        "        # out = x\n",
        "\n",
        "        ############################################################################\n",
        "        \n",
        "        return self_x + self.propagate(edge_index, size=num_nodes, x=self.lin(x))\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! Perform the update step here. \n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        # if self.normalize_emb:\n",
        "            # aggr_out = F.normalize(aggr_out, p=2, dim=-1)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class GAT(pyg_nn.MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, num_heads=1, concat=True,\n",
        "                 dropout=0, bias=True, **kwargs):\n",
        "        super(GAT, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = num_heads\n",
        "        self.concat = concat \n",
        "        self.dropout = dropout\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Define the layers needed for the forward function. \n",
        "        # Remember that the shape of the output depends the number of heads.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin = nn.Linear(in_channels, self.heads * out_channels)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # The attention mechanism is a single feed-forward neural network parametrized\n",
        "        # by weight vector self.att. Define the nn.Parameter needed for the attention\n",
        "        # mechanism here. Remember to consider number of heads for dimension!\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.att = nn.Parameter(torch.Tensor(1, self.heads, 2 * out_channels))\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if bias and concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(self.heads * out_channels))\n",
        "        elif bias and not concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.att)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, edge_index, size=None):\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Apply your linear transformation to the node feature matrix before starting\n",
        "        # to propagate messages.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "        \n",
        "        x = self.lin(x)\n",
        "        ############################################################################\n",
        "\n",
        "        # Start propagating messages.\n",
        "        return self.propagate(edge_index, size=size, x=x)\n",
        "\n",
        "    def message(self, edge_index_i, x_i, x_j, size_i):\n",
        "        #  Constructs messages to node i for each edge (j, i).\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here! Compute the attention coefficients alpha as described\n",
        "        # in equation (7). Remember to be careful of the number of heads with \n",
        "        # dimension!\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        x_j = x_j.view(-1, self.heads, self.out_channels)\n",
        "        x_i = x_i.view(-1, self.heads, self.out_channels)\n",
        "        alpha = (torch.cat((x_i, x_j), dim=-1) * self.att).sum(dim=-1)\n",
        "        alpha = F.leaky_relu(alpha)\n",
        "        alpha = pyg_utils.softmax(alpha, edge_index_i, size_i)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        return x_j * alpha.view(-1, self.heads, 1)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # Updates node embedings.\n",
        "        if self.concat is True:\n",
        "            aggr_out = aggr_out.view(-1, self.heads * self.out_channels)\n",
        "        else:\n",
        "            aggr_out = aggr_out.mean(dim=1)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            aggr_out = aggr_out + self.bias\n",
        "        return aggr_out"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting models.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyOHp1jmf7lW",
        "colab_type": "text"
      },
      "source": [
        "## train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_HoThfIyp91",
        "colab_type": "code",
        "outputId": "123f73d7-ca5e-49d2-cad6-bb4a3a8ed721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import models\n",
        "import utils\n",
        "\n",
        "\n",
        "def arg_parse():\n",
        "    parser = argparse.ArgumentParser(description='GNN arguments.')\n",
        "    utils.parse_optimizer(parser)\n",
        "\n",
        "    parser.add_argument('--model_type', type=str,\n",
        "                        help='Type of GNN model.')\n",
        "    parser.add_argument('--batch_size', type=int,\n",
        "                        help='Training batch size')\n",
        "    parser.add_argument('--num_layers', type=int,\n",
        "                        help='Number of graph conv layers')\n",
        "    parser.add_argument('--hidden_dim', type=int,\n",
        "                        help='Training hidden size')\n",
        "    parser.add_argument('--dropout', type=float,\n",
        "                        help='Dropout rate')\n",
        "    parser.add_argument('--epochs', type=int,\n",
        "                        help='Number of training epochs')\n",
        "    parser.add_argument('--dataset', type=str,\n",
        "                        help='Dataset')\n",
        "\n",
        "    parser.set_defaults(model_type='GCN',\n",
        "                        dataset='cora',\n",
        "                        num_layers=2,\n",
        "                        batch_size=32,\n",
        "                        hidden_dim=32,\n",
        "                        dropout=0.0,\n",
        "                        epochs=200,\n",
        "                        opt='adam',   # opt_parser\n",
        "                        opt_scheduler='none',\n",
        "                        weight_decay=0.0,\n",
        "                        lr=0.01)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def train(dataset, task, args, model_type):\n",
        "    if task == 'graph':\n",
        "        # graph classification: separate dataloader for test set\n",
        "        data_size = len(dataset)\n",
        "        loader = DataLoader(\n",
        "                dataset[:int(data_size * 0.8)], batch_size=args.batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(\n",
        "                dataset[int(data_size * 0.8):], batch_size=args.batch_size, shuffle=True)\n",
        "    elif task == 'node':\n",
        "        # use mask to split train/validation/test\n",
        "        test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    else:\n",
        "        raise RuntimeError('Unknown task')\n",
        "\n",
        "    # build model\n",
        "    model = models.GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
        "                            args, model_type, task=task)\n",
        "    scheduler, opt = utils.build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    accuracies = []\n",
        "    epoch_num = []\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            if task == 'node':\n",
        "                pred = pred[batch.train_mask]\n",
        "                label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        # print(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            test_acc = test(loader, model)\n",
        "            # print(test_acc,   '  test')\n",
        "            accuracies.append(test_acc)\n",
        "            epoch_num.append(epoch)\n",
        "    \n",
        "    return accuracies, epoch_num\n",
        "        \n",
        "\n",
        "def test(loader, model, is_validation=False):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        if model.task == 'node':\n",
        "            mask = data.val_mask if is_validation else data.test_mask\n",
        "            # node classification: only evaluate on nodes in test set\n",
        "            pred = pred[mask]\n",
        "            label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "    \n",
        "    if model.task == 'graph':\n",
        "        total = len(loader.dataset) \n",
        "    else:\n",
        "        total = 0\n",
        "        for data in loader.dataset:\n",
        "            total += torch.sum(data.test_mask).item()\n",
        "    return correct / total\n",
        "\n",
        "def main():\n",
        "    args = arg_parse()\n",
        "\n",
        "    if args.dataset == 'enzymes':\n",
        "        dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "        task = 'graph'\n",
        "    elif args.dataset == 'cora':\n",
        "        dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "        task = 'node'\n",
        "    \n",
        "    print('GCN')\n",
        "    acc_gcn, epoch_num = train(dataset, task, args, 'GCN')\n",
        "    # print('GraphSage')\n",
        "    # acc_gsage, _ = train(dataset, task, args, 'GraphSage')\n",
        "    print('GAT')\n",
        "    acc_gat, _ = train(dataset, task, args, 'GAT')\n",
        "    visualization = pd.DataFrame({\n",
        "        \"epoch\": epoch_num,\n",
        "        \"gcn\": acc_gcn,\n",
        "        # \"graphsage\": acc_gsage,\n",
        "        \"gat\": acc_gat\n",
        "    })\n",
        "    ax = sns.lineplot(x=\"epoch\", y=\"value\", hue=\"variable\", data=pd.melt(visualization, ['epoch']))\n",
        "    file_path = task + '.png'\n",
        "    print(file_path)\n",
        "    ax.figure.savefig(file_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL-aUIbZf0O8",
        "colab_type": "text"
      },
      "source": [
        "## Running run.sh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmBuYTiCYFTV",
        "colab_type": "code",
        "outputId": "8e85410c-b2ae-4e4d-8595-e26482379c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!bash run.sh"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "GCN\n",
            "GAT\n",
            "graph.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsaN3koKplHF",
        "colab_type": "code",
        "outputId": "952c7546-8ba5-44e6-d7a7-21882b2f6844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile run.sh\n",
        "# python train.py --dataset=cora --dropout=0.5 --weight_decay=5e-3 --epochs=500\n",
        "python train.py --dataset=enzymes --weight_decay=5e-3 --num_layers=3 --epochs=500"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting run.sh\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}